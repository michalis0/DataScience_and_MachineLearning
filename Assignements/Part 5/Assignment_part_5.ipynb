{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michalis0/DataScience_and_MachineLearning/blob/master/Assignements/Part%205/Assignment_5_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZu-7QbP9muh"
      },
      "source": [
        "### DSML investigation\n",
        "\n",
        "You are part of the Suisse Impossible Mission Force, or SIMF for short. You need to uncover a rogue agent that is trying to steal sensitive information.\n",
        "\n",
        "Your mission, should you choose to accept it, is to find that agent before stealing any classified information. Good luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyL7WNdV9sWV"
      },
      "source": [
        "# Assignment part five\n",
        "\n",
        "More information came in that suggests that the rogue agent is tampering with the sentiment annotation system of the SIMF which analyses news documents and marks their sentiment for intelligence analysis tasks.\n",
        "\n",
        "This annotation is crucial to identify documents expressing negativity towards Switzerland and its allies.\n",
        "\n",
        "Each document contains a column which shows which user accessed it. We know that the rogue agent accessed only the documents whose negative sentiment was high, and then changed them to positive or neutral. We will use a huggingface model to identify which records have been tampered with.\n",
        "\n",
        "\n",
        "[You can find more models on this link](https://huggingface.co/models?sort=trending)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R60Qc6KIxIii"
      },
      "outputs": [],
      "source": [
        "# Install the required libraries (you need to run this cell ONLY if you are running the notebook locally)\n",
        "# No need to run this cell in colab!\n",
        "%%capture\n",
        "!pip install datasets transformers huggingface_hub\n",
        "!apt-get install git-lfs\n",
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U\n",
        "!pip install openpyxl\n",
        "\n",
        "!pip install -q transformers\n",
        "%pip install ipywidgets\n",
        "%pip install --upgrade transformers huggingface_hub torch\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XHhI95r5-tyD"
      },
      "outputs": [],
      "source": [
        "# Import required packages\n",
        "from transformers import pipeline, DataCollatorWithPadding\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "torch.cuda.is_available()\n",
        "\n",
        "# Import standard libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import bs4 as bs\n",
        "import urllib.request\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interact, interact_manual\n",
        "\n",
        "# Import for text analytics\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "\n",
        "# Import metrics libraries\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx8xYrO4CxL-"
      },
      "source": [
        "# 1. Getting to know our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RGE_4cFOqxbg"
      },
      "outputs": [],
      "source": [
        "\n",
        "df = pd.read_excel('https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/master/Assignements/Part%205/data/Reduced_Set_2100.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fb3Onvokqxbh"
      },
      "outputs": [],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmH1uBydDB9b"
      },
      "source": [
        "### 2. Re-evaluating with SIMF's Model\n",
        "\n",
        "We will re-evaluate the sentiment on the `title` column using a sentiment analysis pipeline based on the `finiteautomata/bertweet-base-sentiment-analysis` model. This is a sentiment analysis model trained on ~40k tweets. It classifies a text as `POS` (positive), `NEU` (neutral), or `NEG` (negative) sentiment.\n",
        "\n",
        "Initialize a sentiment analysis classifier with the pre-trained model mentioned above, making sure to set the correct value for the `task` parameter.\n",
        "\n",
        "**Note**: Set the `top_k` argument to `None` to retrieve the probabilities for all possible sentiment labels in the output.\n",
        "\n",
        "_This process may take some time._"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3TGz8z4Dfh9"
      },
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwY5FlKdxIil"
      },
      "source": [
        "Apply the sentiment classifier to the `title` column and assign the corresponding sentiment labels to a new column in your dataframe.\n",
        "\n",
        "Make sure to convert the sentiment labels from the model by replacing them with more descriptive terms like this:\n",
        "- **NEU**: neutral\n",
        "- **NEG**: negative\n",
        "- **POS**: positive\n",
        "\n",
        "*Hint: Be mindful of the format of the classifierâ€™s output.*\n",
        "\n",
        "_Beware that applying the model on all of the rows may take some time_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52DDFGFhxIim"
      },
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYTPy_oTxIim"
      },
      "source": [
        "Now, display the number of unique sentiment evaluations for both the Hugging Face and SIMF models to compare the distribution of labels.\n",
        "\n",
        "Next, calculate and display the accuracy of the Hugging Face sentiment analysis compared to the SIMF evaluation. Finally, visualize the comparison using a heatmap of the confusion matrix to better understand where the two models align or differ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjA4YLYoxIim"
      },
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq_JFAuixIim"
      },
      "source": [
        "**Q1. Does the SIMF sentiment classifier predicts more samples to be \"neutral\"  compared to the Hugging Face sentiment classifier?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_RlHub7zdml"
      },
      "source": [
        "## 2.1 Entries match both the SIMF model **and** the hugginface model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qup5cwL79D4E"
      },
      "source": [
        "The SIMF model values are found in the `evaluation` column, while the hugginface model values should be found in the `new_column`, which you added to the table in the previous step.\n",
        "\n",
        "Display:\n",
        "*   The rows/records with same sentiment for both models.\n",
        "*   The number of matching values.\n",
        "*   The share of matching values of the total number of values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiNq8Ao-zdUh"
      },
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrpDo55srrTs"
      },
      "source": [
        "**Q2. How many entries are identical between the SIMF model evaluation and the Hugging Face model evaluation?**\n",
        "\n",
        "*Note: Provide your answer as an integer (e.g., 80).*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7nH3eY5y82X"
      },
      "source": [
        "## 2.2 Entries that do not match both models\n",
        "Identify all non matching entries.\n",
        "\n",
        "Create a subset with all the entries that were evaluated differently by the two models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZfbRN8Y-O4V"
      },
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-XZXkjm1uzk"
      },
      "source": [
        "## 2.3 Predicted negative, but evaluated as neutral or positive by the SIMF model\n",
        "\n",
        "Remember, we are looking at document that were tempered (altered). We suspect that the rogue agent accessed only the documents whose negative sentiment was high, and was then changed to positive or neutral.\n",
        "\n",
        "Create a subset with only those values, which appear as 'positive' or 'neutral' in the original `evaluation` column, but are marked as having a 'negative' sentiment by the new hugginface model.\n",
        "\n",
        "**This subset is what we'll call the end of the assignment : \"Altered Documents\".**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgZtQbdl19Ek"
      },
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9WpRfTgsn6E"
      },
      "source": [
        "**Q3. How many entries were changed from a negative evaluation (in the Hugging Face model) to a neutral or positive evaluation (by the SIMF model)?**\n",
        "\n",
        "*Note: Provide your answer as an integer (e.g., 45).*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKzgCDAq7_6O"
      },
      "source": [
        "# 3. Use the ChangeLog dataframe to identify the usersID's who edited the entries.\n",
        "\n",
        "Consider the subset you created in the previous step : *the altered documents*.\n",
        "\n",
        "By combining it with ChangeLog, display only those userIDs, that belong to the people who tried to mask the 'negative' sentiments by assigning these sentences a 'positive' or 'neutral' value.\n",
        "\n",
        "In other words, match the previous subset with corresponding UserIDs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjA97Cfv9g_j"
      },
      "outputs": [],
      "source": [
        "ChangeLog = pd.read_csv('https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/master/Assignements/Part%205/data/ChangeLogFix.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ij13vHl4xIio"
      },
      "outputs": [],
      "source": [
        "display(ChangeLog.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7-jmLjkUC1J"
      },
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdaJ0lqhtJpl"
      },
      "source": [
        "**Q4. Which of the following users remain suspects when considering only the documents evaluated as negative by the Hugging Face model but not by the SIMF model?**\n",
        "\n",
        "*Note: Select among the following answers*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3Zo8voPe-fP"
      },
      "source": [
        "### 4. Identifying Key Information in the Altered Documents\n",
        "\n",
        "In this section, we will use the **TF-IDF** (Term Frequency-Inverse Document Frequency) features to identify significant terms in the *altered documents*.\n",
        "\n",
        "Start by creating a list of all the original texts from the `news` column in the dataframe `df`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C_OfWwzN_4yE"
      },
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Euj_Ue1PxIip"
      },
      "source": [
        "\n",
        "Initialize the `TfidfVectorizer` with unigrams (`ngram_range=(1, 1)`) and set the `stop_words` parameter to `'english'` to exclude common English words from the analysis.\n",
        "\n",
        "\n",
        "Apply the vectorizer to the corpus of text and convert the resulting document-term matrix into a DataFrame for easy visualization and analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTSH1vJRAGqg"
      },
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKyk8MQUxIip"
      },
      "source": [
        "We now want to focus solely on the **\"altered documents\"**.\n",
        "\n",
        "To do this, use the previously created list that contains the documents where the Hugging Face model gave a **negative** evaluation, but the SIMF model evaluated them as **neutral** or **positive**.\n",
        "\n",
        "From this list of documents, extract the corresponding text from the `news` column to obtain a list of articles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSPoVKNvTCIO"
      },
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_Dp3Q-CxIip"
      },
      "source": [
        "Now, we will identify the document that stands out the most among the altered documents based on the TF-IDF values.\n",
        "\n",
        "1. **Filter the TF-IDF DataFrame**: Keep only the entries from the `tfidf_df` that correspond to the tampered documents.\n",
        "   \n",
        "2. **Sum TF-IDF Values**: For each tampered document, calculate the sum of the TF-IDF values across all tokens. This gives an overall importance score for each document.\n",
        "\n",
        "3. **Find the Most Significant Document**: Identify the document with the highest summed TF-IDF value, which stands out the most. Retrieve its index from the original DataFrame `df` and display the details of this document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5XjV3YFAPOC"
      },
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i6Qw0kW_xIiq"
      },
      "source": [
        "**Q5. What is the name's company of the most important altered document?**\n",
        "\n",
        "*Note: The most important altered document means the document with the highest summed TF-IDF value.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGx644rQxIiq"
      },
      "source": [
        "Now, across the altered documents, let's identify the words that stand out the most, meaning those with the highest summed TF-IDF values.\n",
        "\n",
        "To achieve this, sum the values of each column in the altered TF-IDF dataframe, since each column represents a token. Then, sort these summed values in descending order to easily identify the top 4 words with the highest TF-IDF scores.\n",
        "\n",
        "Once you have these top 4 words, count in how many *altered documents* each top word appeared."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ep6xpyfATli"
      },
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SOTh6dPyaE3"
      },
      "source": [
        "**Q6. What is the token with the highest summed TF-IDF value?**\n",
        "\n",
        "*Note: Select among the following answers*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Flc1j2pxIiv"
      },
      "source": [
        "**Q7. In how many altered documents do the third most frequent word appeared ?**\n",
        "\n",
        "*Note: Provide your answer as an integer (e.g., 45).*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Your investigation is progressing effectively, and the list of suspects is narrowing down.\n",
        "\n",
        "**Don't forget to answer the quiz and submit your code on Moodle before the end of the deadline.**"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
