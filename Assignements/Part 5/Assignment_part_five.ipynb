{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/michalis0/DataScience_and_MachineLearning/blob/master/Assignements/Part%205/Assignment_part_five.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZu-7QbP9muh"
      },
      "source": [
        "DSML investigation:\n",
        "\n",
        "You are part of the Suisse Impossible Mission Force, or SIMF for short. You need to uncover a rogue agent that is trying to steal sensitive information.\n",
        "\n",
        "Your mission, should you choose to accept it, is to find that agent before stealing any classified information. Good luck!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyL7WNdV9sWV"
      },
      "source": [
        "# Assignement part five\n",
        "\n",
        "### Due 29.10 (You get an extra hour!)\n",
        "\n",
        "By now you should have 19 suspects left.\n",
        "More information came in that suggests that the rogue agent is tampering with the sentiment annotation system of the SIMF which analyses news documents and marks their sentiment of intelligence analysis tasks.\n",
        "\n",
        "This annotation is crutial to identify documents expressing negativity towards Switzerland and its allies.\n",
        "\n",
        "Each document contains a column which shows which user accessed it. We know that the rogue agent accessed only the documents whose probability of negative sentiment was between 0.4 and 0.5 initially and beween 0.1 and 0.2 according to the SIMF classifier which you can load onto your model.\n",
        "\n",
        "\n",
        "[You can find more models on this link](https://huggingface.co/models?sort=trending)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHhI95r5-tyD",
        "outputId": "516818b8-83db-4be2-a607-5e47278fa763"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-10-23 14:12:37.433277: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "%%capture\n",
        "!pip install datasets transformers huggingface_hub\n",
        "!apt-get install git-lfs\n",
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U\n",
        "# Import required packages\n",
        "from transformers import pipeline, DataCollatorWithPadding\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "torch.cuda.is_available()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx8xYrO4CxL-"
      },
      "source": [
        "# 1. Getting to know our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGE_4cFOqxbg"
      },
      "outputs": [],
      "source": [
        "df = pd.read_excel('https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/master/Assignements/Part%205/data/Reduced_Set_2100.xlsx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "Fb3Onvokqxbh",
        "outputId": "7aefeed1-a714-47ab-fa42-7cc7e51ecee4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>company</th>\n",
              "      <th>title</th>\n",
              "      <th>news</th>\n",
              "      <th>evaluation</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>APPLE</td>\n",
              "      <td>Tourists snap up British iPads to smuggle into...</td>\n",
              "      <td>IT'S the digital version of the slow boat to C...</td>\n",
              "      <td>negative</td>\n",
              "      <td>2011</td>\n",
              "      <td>4</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CHEVRON</td>\n",
              "      <td>AFTER SEATTLE; Anarchists get organized.</td>\n",
              "      <td>For Juliette Beck, it began with the story of ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>2000</td>\n",
              "      <td>4</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   company                                              title  \\\n",
              "0   APPLE   Tourists snap up British iPads to smuggle into...   \n",
              "1  CHEVRON           AFTER SEATTLE; Anarchists get organized.   \n",
              "\n",
              "                                                news evaluation  year  month  \\\n",
              "0  IT'S the digital version of the slow boat to C...   negative  2011      4   \n",
              "1  For Juliette Beck, it began with the story of ...   negative  2000      4   \n",
              "\n",
              "  day  \n",
              "0  17  \n",
              "1  17  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmH1uBydDB9b"
      },
      "source": [
        "# 2. Re-evaluating with SIMF's model:\n",
        "Evaluate the sentiment on the title column using a sentiment pipeline trained on the `finiteautomata/bertweet-base-sentiment-analysis`model\n",
        "\n",
        "\n",
        "_This may take a while_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N3TGz8z4Dfh9"
      },
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XScEdGvVqxbi"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_RlHub7zdml"
      },
      "source": [
        "## 2.1 How many of the total entries match both the SIMF model **and** the hugginface model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WiNq8Ao-zdUh"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7nH3eY5y82X"
      },
      "source": [
        "## 2.2 We will now focus on the entries that do not match\n",
        "#### Identify all non matching entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZfbRN8Y-O4V"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-XZXkjm1uzk"
      },
      "source": [
        "## 2.3 How many of those entries that our model predicted as negative, are evaluate as neutral or positive by the SIMF model ?\n",
        "\n",
        "Store the resulting dataframe into a new one that we will be using in the following questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgZtQbdl19Ek"
      },
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKzgCDAq7_6O"
      },
      "source": [
        "# 3. Use the ChangeLog dataframe to identify the usersID's who edited the tampered entries, and only the altered entries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FjA97Cfv9g_j"
      },
      "outputs": [],
      "source": [
        "ChangeLog = pd.read_csv('https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/master/Assignements/Part%205/data/ChangeLog.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6uH3PNtJ9WHE"
      },
      "source": [
        "## 3.1 Identifying the users who have edited tampered documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s8j0Rxhx9f8X"
      },
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRaNc7a89VVm"
      },
      "source": [
        "## 3.2 Identifying the users who have edited non-tampered documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67nWYmT_BYIq"
      },
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrI3MKddC3UY"
      },
      "source": [
        "## 3.3 combining the results from `3.1` and `3.2` to identify users who only edited tampered documents.\n",
        "These are our suspects."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYl5RvF7DFcj"
      },
      "outputs": [],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3Zo8voPe-fP"
      },
      "source": [
        "# 4. Identifying important informations on the altered documents.\n",
        "\n",
        "In this section we will use the TF-IDF text representation model to identify other important information on the altered documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSPoVKNvTCIO"
      },
      "outputs": [],
      "source": [
        "# Make a list of the text within articles with the original dataset (the one of section 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pew__A22TA8r"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "# Using default tokenizer in TfidfVectorizer, use the \"english\" stop words, and unigrams\n",
        "\n",
        "# Learn the vocabulary dictionary and return document-term matrix\n",
        "\n",
        "# Visualize result in dataframe\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zo22PIjw1b13"
      },
      "outputs": [],
      "source": [
        "# Keep the entries related to tampered documents\n",
        "\n",
        "# Identify the record that stands out the most on the altered documents (you can use the sum of the tokenizers results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "485rSW0X4ShW"
      },
      "outputs": [],
      "source": [
        "# How many records contain the word that stands out the most?\n",
        "# e.g. if the word that stood out the most was \"mouton\", how many of the altered records contain the word mouton.\n",
        "\n",
        "# How about the second word that stands out the most\n",
        "\n",
        "# How about the third ?\n",
        "\n",
        "# How about the fourth ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK2MBdTr7KfK"
      },
      "source": [
        "#### Moodle quizz: if the order of frequency in appearance, did not match the values assigned by the tokenizer, is it normal?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
