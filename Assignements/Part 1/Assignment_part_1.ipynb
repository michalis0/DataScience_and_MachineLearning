{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/michalis0/DataScience_and_MachineLearning/blob/master/Assignements/Part%201/Assignment_part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "yrXLb3bx4cfD"
   },
   "source": [
    "# DSML investigation:\n",
    "### You are part of the Suisse Impossible Mission Force, or SIMF for short. You need to uncover a rogue agent that is trying to steal sensitive information.\n",
    "\n",
    "### Your mission, should you choose to accept it, is to find that agent before any classified information gets stolen. Good luck!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "4bVDcyJHHFjh"
   },
   "source": [
    "## Assignment part one\n",
    "\n",
    "Airport security confiscated a laptop of a spy, which was later given to you. The laptop contains some documents that might be useful in the investigation process. You retrieve those documents and want to analyse them. Our intelligence shows that the person that we are looking for has visited the USA between Sept 2019 to Oct 2020. He is currently working undercover.\n",
    "\n",
    "\n",
    "### Getting to know our data\n",
    "\n",
    "We have retrieved from the laptop the following file:\n",
    "- A list of suspects\n",
    "- The flight records of these potential suspects\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "abwjDTZRHvzn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "userRecords = pd.read_csv(\"https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/refs/heads/master/Assignements/Part%201/data/userRecords.csv\")\n",
    "travelRecords = pd.read_csv(\"https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/refs/heads/master/Assignements/Part%201/data/flightRecords.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fl_HmWwtIBDJ"
   },
   "source": [
    "#### Shape of the data\n",
    "\n",
    "Let's first check how many rows and columns (features) are in the user records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uICj1b0GIEKG"
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "2XIhLUBJDmfq"
   },
   "source": [
    "**Q1. How many rows are there in the user records dataset?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "JT6l8O-2ISqh"
   },
   "source": [
    "\n",
    "#### Check out the first few rows\n",
    "Print the first few rows of the user records dataset and check them. Note that to protect innocent people, the name of the suspects have been censored, those will be revealed once number of potential suspects decreases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xce5aB8SIOeu"
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "3TgOsG-pI8Yo"
   },
   "source": [
    "#### Column/feature names\n",
    "print the list of columns in the user records dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KPRr2ogtI-3B"
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "e1XYn9tvJHbL"
   },
   "source": [
    "#### Duplicates\n",
    "Check if there are any duplicate entries in the user records dataset.\n",
    "\n",
    "__Remark__: If there are two rows in the dataset that have the same value for __all of the columns__, we consider this as a duplicate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ve6cJ5hbJIrQ"
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "tebuO3lxJP-_"
   },
   "source": [
    "Show all the duplicated rows in the user records dataset.\n",
    "\n",
    "__Hint:__ use the method `duplicated(keep=False)` to get all occurrences of the duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5UPbuQn5JQnQ"
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "qj3ec2_dD7OZ"
   },
   "source": [
    "**Q2. Are there any duplicate entries in the user records dataset?**\n",
    "\n",
    "*Note: Duplicate entries refer to two or more rows where all the values across every column are identical.*"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "LvIVdCfzEE64"
   },
   "source": [
    "**Q3. How many duplicate entries are in the user records dataset?**\n",
    "\n",
    "(Remark: for instance: there are 2 duplicate \"entries\" in the following list: '1 ,2, 1, 3, 3, 4, 5'. It's 1 and 3)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "AdTka1hDgpUB"
   },
   "source": [
    "Drop the duplicate entries in the user records dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jp9ndUSZgtSj"
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "pLJGJqwPT8B9"
   },
   "source": [
    "### Spies often use false identities with fabricated data.\n",
    "\n",
    "#### This suggests that if certain data points occur with statistically improbable frequency, they might be fabricated.\n",
    "\n",
    "In this part we are going to verify if there are birthdates that have been reused an unusual amount of times."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Qm2RR5j8Ky-t"
   },
   "source": [
    "Let's first ensure that the birthday column in the user records dataset has the correct format (datetime):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJ1-Bk2XULlt"
   },
   "outputs": [],
   "source": [
    "#Check the data type of each feature\n",
    "#Your code here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "m1Bf_f-9qYTa"
   },
   "source": [
    "Convert the column `birthday` to datetime if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3hmp9zVZK8fY"
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZtNDR-qOzFfQ"
   },
   "source": [
    "Find the list of birthdays that are duplicated/reused in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R7xDb_JPyD0x"
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdIP5xyv2Qfs"
   },
   "source": [
    "Let's count how many people have their birthday on the same day among the duplicated birthdays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JDXzbAGPzVXy"
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVtdeKq7E4Bl"
   },
   "source": [
    "**Q4. What is the most common birthday in the dataset?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrP661RxFBt2"
   },
   "source": [
    "**Q5. How many users have their birthdays on that day (the most common birthday)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8hVJ7zM4RZk4"
   },
   "source": [
    "We can consider that there is no suspicious discrepancy through birthdays.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-Akjuv9hBsPg"
   },
   "source": [
    "#### We have reasons to believe that the suspect works very thoroughly, so he would make sure that the fabricated data about his identity is complete in order for his operation to run smoothly.\n",
    "#### Therefore, we can exclude the people with incomplete information from the list of potential suspects."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OH0Rp5xb3OH9"
   },
   "source": [
    "Count how many null values are there in each column of the user records dataset. You can call `isnull()` and `sum()` to get a count of how many null values are there in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27y9FBJG3MuR"
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b383FA5V0PfJ"
   },
   "source": [
    "If you encounter any null values in the dataset, be sure to exclude those entries from the suspect list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OxZ-tXn10mAg"
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "KkWJBx21Cq41"
   },
   "source": [
    "### Linking the user records to the flight records\n",
    "\n",
    "We will now proceed to identify the users who were in the USA from Sept 1st, 2019 to Oct 31st, 2020.\n",
    "\n",
    "We will merge the flight records with the user records in order to ensure that users who have been unsuspected in the previous step are not considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EL7JbTKQCqUR"
   },
   "outputs": [],
   "source": [
    "#check the user records dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C8XXKKWVGa5_"
   },
   "outputs": [],
   "source": [
    "#check the flight records dataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Mp1SB0TPKoKM"
   },
   "source": [
    "[Merging](https://pandas.pydata.org/docs/user_guide/merging.html) the two datasets:\n",
    "\n",
    "*Hint: Use the above questions to identify on what feature to merge the datasets*\n",
    "\n",
    "The result should contain the features flightName, Departure, Arrival,  Date, UserID, first_name, last_name, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJbpo03uHBcW"
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qe8pzJ5A1TxQ"
   },
   "source": [
    "Remember, our suspect operates meticulously, ensuring that there are no null values in any entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5HWgNzpC1pmL"
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "wmVg_OcqCzPe"
   },
   "source": [
    "Let's now identify the users who has **travelled to** the United States (US) between the 1st of september 2019 and the 31st of october 2020.\n",
    "\n",
    "*Note that the travel date is not in datetime format.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1qFGYqCsCynF"
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MoLO1Mz5IIZT"
   },
   "source": [
    "**Q6. How many suspects travelled to the US between the 1st of September 2019 and the 31st of October 2020?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7. Which users are included in the remaining list of suspects who traveled to the US between the 1st of September 2019 and the 31st of October 2020?** Choose from the answers on Moodle."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "6nh27RK8cMJZ"
   },
   "source": [
    "## [Data visualisation ](https://pandas.pydata.org/docs/user_guide/visualization.html)\n",
    "\n",
    " Suisse Impossible Mission Force is happy with the result and would like to have some visual aid to make a profile of the potential suspects."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "5mX8w6H7c6ro"
   },
   "source": [
    "Let's create a pie chart to visualize the employment distribution among the suspects who traveled to US between September 1st, 2019, and October 31st, 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Muyk-xMc7h6"
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "M9Neo8lE3wd9"
   },
   "source": [
    "**Q8. Which profession is the least represented among the suspects the suspects who traveled to US between September 1st, 2019, and October 31st, 2020?**\n",
    " Choose from the answers on Moodle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBUy4QHHiWuO"
   },
   "source": [
    "## Journey length\n",
    "\n",
    "The Suisse Impossible Mission Force suspects that the rogue agent is an anomaly within his declared employment category, particularly in terms of the number of days he spent at destinations compared to his peers.\n",
    "\n",
    "To identify such deviations, we can employ boxplots for each employment category, allowing us to visually identify outliers in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiKyLYwHcCJ-"
   },
   "source": [
    "First, let's construct two tables: one for the dates of arrival and another for the dates of departure. Utilize the existing dataset to extract these dates based on the 'destination' and 'departure' columns. Ensure that both the arrival and departure dates are within the period the suspect is believed to have been in the US, which is from September 2019 to October 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pZvGcHwbv0e7"
   },
   "outputs": [],
   "source": [
    "# For this step we will need the information not only about the fights to the US, \n",
    "# but also about the flights taken from the US\n",
    "# Your code here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "_gXDZXu0LUa5"
   },
   "source": [
    "We can keep on both of these tables the user ID, employment, and departure date / arrival date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0m_fOp5LLjnq"
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zJR7PDWZL3oO"
   },
   "source": [
    "We can now join the two tables on user ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9INyxNK9L3aC"
   },
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "NK1vMch6MhsP"
   },
   "source": [
    "We can now create a new feature called journey_length representing the difference between departure date and arrival date.\n",
    "\n",
    "*Hint: Ensure that the journey_length is in the right format*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6TFymz0VMxaU"
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ySuTXWou8wSf"
   },
   "source": [
    "*Sidenote: if you get negative journey length, what would be your explanation to that?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nnlu7m3kPBEV"
   },
   "source": [
    "We can now create the boxplots where the x-axis represents each profession and the y-axis corresponds to the journey length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nH9H5M18PDrm"
   },
   "outputs": [],
   "source": [
    "#Your code here\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "SM4NCHMMJz8K"
   },
   "source": [
    "**Q9. Which profession has the most staggering outlier?**\n",
    "(Meaning that the outlier value is the farthest away from the corresponding boxplot.)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "BqQD6lffRdNW"
   },
   "source": [
    "### SIMF is satisfied with your work but believes the current data is inconclusive.\n",
    "\n",
    "Your investigation will continue when more intelligence comes in..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "GUc8izkj48y2"
   },
   "source": [
    "**Don't forget to complete the moodle quiz ([Assignment Q1](https://moodle.unil.ch/mod/quiz/view.php?id=1744562)) and submit your code ([Code Q1](https://moodle.unil.ch/mod/assign/view.php?id=1744563)) on Moodle before Monday 30.09.2024.**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
