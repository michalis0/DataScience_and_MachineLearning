{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michalis0/DataScience_and_MachineLearning/blob/master/06-recommender-systems/Week_06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OHM0r5z2CeJU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "U26TtWpHCeJW"
      },
      "source": [
        "# Recommender Systems"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "j6-XVoQNCeJW"
      },
      "source": [
        "\n",
        "<img src='https://imgs.xkcd.com/comics/star_ratings.png' width=\"300\">\n",
        "\n",
        "Source: [xkcd 1908](https://xkcd.com/1098/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pklpI_Q7CeJX"
      },
      "source": [
        "### Goal\n",
        "In this exercise, we will be proceeding in two stages.\n",
        "1. The first stage is where we get into the details of how to build our own recommender system to recommend movies to users.\n",
        "2. In the second stage, we will be an existing library, specialized for recommender systems, which provides more powerful options. We will be testing it on the task of recommending jokes to users.\n",
        "\n",
        "### What you are learning in this exercise:\n",
        "1. Getting familiar with item-based collaborative filtering and user-based collaborative filtering.\n",
        "2. Getting familiar with an existing library for recommender systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12CwjzRmCeJX"
      },
      "source": [
        "### Content\n",
        "\n",
        "The goal of this walkthrough is to guide you through implementing and evaluating a basic recommender system. A [recommender system](https://en.wikipedia.org/wiki/Recommender_system) is a type of information filtering system designed to predict a user’s preference for an item, often used in commercial applications to suggest products, movies, or other items.\n",
        "\n",
        "In this notebook, we will cover:\n",
        "\n",
        "- [Task 1: Exploring the MovieLens Dataset with Implicit Feedback](#Task-1-Exploring-the-MovieLens-Dataset-with-Implicit-Feedback)\n",
        "  - [Step 1: Load the Data](#Step-1-Load-the-Data)\n",
        "  - [Step 2: Check the Number of Interactions, Users, and Movies](#Step-2-Check-the-Number-of-Interactions-Users-and-Movies)\n",
        "  - [Step 3: Split the Data into Training and Test Sets](#Step-3-Split-the-Data-into-Training-and-Test-Sets)\n",
        "  \n",
        "- [Task 2: Creating User-Item Matrices for Implicit Feedback](#Task-2-Creating-User-Item-Matrices-for-Implicit-Feedback)\n",
        "  - [Step 1: Define the Function to Create the Data Matrix](#Step-1-Define-the-Function-to-Create-the-Data-Matrix)\n",
        "  - [Step 2: Create the Training and Testing Matrices](#Step-2-Create-the-Training-and-Testing-Matrices)\n",
        "  - [Step 3: Visualize the User-Item Interaction Matrices](#Step-3-Visualize-the-User-Item-Interaction-Matrices)\n",
        "\n",
        "- [Task 3: Item-to-Item Collaborative Filtering with Implicit Feedback](#Task-3-Item-to-Item-Collaborative-Filtering-with-Implicit-Feedback)\n",
        "  - [Step 1: Compute Item Similarity Matrix](#Step-1-Compute-Item-Similarity-Matrix)\n",
        "  - [Step 2: Predict Positive Interactions Using Item Similarity](#Step-2-Predict-Positive-Interactions-Using-Item-Similarity)\n",
        "\n",
        "- [Task 4: User-to-User Collaborative Filtering with Implicit Feedback](#Task-4-User-to-User-Collaborative-Filtering-with-Implicit-Feedback)\n",
        "  - [Step 1: Compute User Similarity Matrix](#Step-1-Compute-User-Similarity-Matrix)\n",
        "  - [Step 2: Predict Positive Interactions Using User Similarity](#Step-2-Predict-Positive-Interactions-Using-User-Similarity)\n",
        "\n",
        "- [Task 5: Evaluating Our Recommenders](#Task-5-Evaluating-Our-Recommenders)\n",
        "  - [Step 5.1: Precision@K and Recall@K](#Step-5.1-Precision@K-and-Recall@K)\n",
        "  - [Step 5.2: Implement Precision@K and Recall@K](#Step-5.2-Implement-Precision@K-and-Recall@K)\n",
        "\n",
        "- [Task 6: Show the Recommendations for a Specific User](#Task-6-Show-the-Recommendations-for-a-Specific-User)\n",
        "  - [Step 6.1: Select a User and Get Recommendations](#Step-6.1-Select-a-User-and-Get-Recommendations)\n",
        "  - [Step 6.2: Create Recommendation DataFrames with TMDb IDs](#Step-6.2-Create-Recommendation-DataFrames-with-TMDb-IDs)\n",
        "  - [Step 6.3: Fetching and Displaying Movie Posters](#Step-6.3-Fetching-and-Displaying-Movie-Posters)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "IMEUUjU8CeJY"
      },
      "source": [
        "## Task 1: Exploring the MovieLens Dataset with Implicit Feedback\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "je0wdpXZCeJY"
      },
      "source": [
        "In this part, we’ll be using the [MovieLens dataset](https://grouplens.org/datasets/movielens/). ‌We will use the Movielens-small dataset that contains 100,000 interactions of users with different movies. An interaction of a user with a movie is when a user rates a movie with a value from 1 to 5. In this walkthrough we want to focus on **implicit feedback** recommendation scenario, i.e., we are interested in the items that each user liked, or interacted with. Therefore, we have provided you with a subset of interactions in the dataset that contains the ratings larger than or equal to 4."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmU6sB5JCeJY"
      },
      "source": [
        "#### Step 1: Load the Data\n",
        "\n",
        "We’ll start by loading the datasets in the `data` folder. We have 3 datasets here:\n",
        "- `interactions.csv`\n",
        "- `movies.csv`\n",
        "- `links.csv`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 584
        },
        "id": "uthVzXlRCeJZ",
        "outputId": "447cc3af-a98e-42b5-ca20-050af38d1d9a"
      },
      "outputs": [],
      "source": [
        "# Load the datasets\n",
        "interactions = pd.read_csv('https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/refs/heads/master/Labs/06-recommender-systems/data/interactions.csv')\n",
        "movies = pd.read_csv(\"https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/refs/heads/master/Labs/06-recommender-systems/data/movies.csv\")\n",
        "links = pd.read_csv(\"https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/refs/heads/master/Labs/06-recommender-systems/data/links.csv\")\n",
        "# Display the first rows of each dataset\n",
        "display(interactions.head())\n",
        "display(movies.head())\n",
        "display(links.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCV2GtmtSh6w"
      },
      "source": [
        "__Can you understand the information contained in each of the tables above?__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GeQ_ys3CeJa"
      },
      "source": [
        "\n",
        "#### Step 2: Check the Number of interactions, users and movies\n",
        "\n",
        "Let’s check how many unique users and items we have in this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHDaQs3tCeJb",
        "outputId": "2c291264-9e5a-49c3-c805-8852a89117e7"
      },
      "outputs": [],
      "source": [
        "n_users = interactions.user_id.nunique()\n",
        "n_items = interactions.movie_id.nunique()\n",
        "print(f'Number of users = {n_users}, \\n Number of movies = {n_items} \\n Number of interactions = {len(interactions)}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ02IWmrCeJb"
      },
      "source": [
        "\n",
        "#### Step 3: Split the Data into Training and Test Sets\n",
        "\n",
        "Splitting the data to training and test sets for recommendation systems is different from what you have seen in other classification/regression problems. In recommender systems, we want to make recommendations (predictions) for each user. Therefore, we need to make sure that we have training and test data for each user. In other words, we have to split the interactions of each user to training and test sets. For instance, if we want to do 80-20 splitting, we need to make sure that we have 80% of each user's interactions in the training set and the remaining 20% in the test set.\n",
        "\n",
        "Moreover, to have a splitting that is more aligned with the reality, it is better to do the splitting based on the timestamp of the interactions (if the timestamp data is available). To do so, we have to sort the interactions of each user based on time, and pick the first 80% interactions in the training set and the last 20% interactions in the test set. This is more aligned with the reality as we always want to predict the future interactions of a user, that is, *the items that the user might like in the future*.\n",
        "\n",
        "The figure below can help you understand better how this splitting is done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/refs/heads/master/09-recommender-systems/data/image/train-test-split-reco.png' width=\"700\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "gd32QvvuZWac",
        "outputId": "e72296d1-8638-4b6b-e8e3-ca289c73ff25"
      },
      "outputs": [],
      "source": [
        "# let's first sort the interactions by user and time stamp\n",
        "interactions = interactions.sort_values([\"user_id\", \"timestamp\"])\n",
        "interactions.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TH4vwOSeZ0Js"
      },
      "source": [
        "Next we can use the percentage rank from pandas to get a proportional ranking of the timestamps for each user. Check the documentation on how to use the `rank` funciton with groupby in pandas (https://pandas.pydata.org/docs/reference/api/pandas.core.groupby.DataFrameGroupBy.rank.html#pandas.core.groupby.DataFrameGroupBy.rank)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "_nG-g8CoZuFM",
        "outputId": "04b07330-c379-4488-87f9-463ab9962f97"
      },
      "outputs": [],
      "source": [
        "interactions[\"pct_rank\"] = interactions.groupby(\"user_id\")[\"timestamp\"].rank(pct=True, method='dense')\n",
        "interactions.reset_index(inplace=True, drop=True)\n",
        "interactions.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JaLSrKya5P6"
      },
      "source": [
        "Now all remains to do is to pick the first 80% of the interactions of each user in the training set and the rest in the test set. We can do so using the `pct_rank` column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "keedrU6da4Kd"
      },
      "outputs": [],
      "source": [
        "train_data = interactions[interactions[\"pct_rank\"] < 0.8]\n",
        "test_data = interactions[interactions[\"pct_rank\"] >= 0.8]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P68b_ijzCeJb",
        "outputId": "ed6a9104-2091-4f8e-a317-d2212c322ce0"
      },
      "outputs": [],
      "source": [
        "print(\"Training set size:\", train_data.shape[0])\n",
        "print(\"Testing set size:\", test_data.shape[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qX6z1MoCeJb"
      },
      "source": [
        "## Task 2: Creating User-Item Matrices for Implicit Feedback\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv7ZMDzNCeJc",
        "outputId": "a2d6334b-6c14-40b3-818a-be25d324362c"
      },
      "outputs": [],
      "source": [
        "\n",
        "print('number of users =', n_users, '| number of movies =', n_items)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4WD0VpYCeJc"
      },
      "source": [
        "#### Step 1: Define the Function to Create the Data Matrix\n",
        "\n",
        "Next, we’ll define a function that creates the user-item data matrix. Each matrix cell will contain a 1 if there was an interaction and a 0 otherwise.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3hk-nUZgCeJc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define a function to create the data matrix\n",
        "def create_data_matrix(data, n_users, n_items):\n",
        "    \"\"\"\n",
        "    This function returns a numpy matrix with shape (n_users, n_items).\n",
        "    Each entry is a binary value indicating positive interaction.\n",
        "    \"\"\"\n",
        "    data_matrix = np.zeros((n_users, n_items))\n",
        "    data_matrix[data[\"user_id\"].values, data[\"movie_id\"].values] = 1\n",
        "    return data_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnvgOARgCeJc"
      },
      "source": [
        "#### Step 2: Create the Training and Testing Matrices\n",
        "\n",
        "Now we can use the function to create matrices for both the training and testing data. Each cell in the matrix will show a 1 if there was a positive interaction in the training or testing data, and a 0 otherwise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFQ62rQWCeJc",
        "outputId": "76dc7e19-18a3-42f7-cacf-c72185f90f19"
      },
      "outputs": [],
      "source": [
        "# Create the training and testing matrices\n",
        "train_data_matrix = create_data_matrix(train_data, n_users, n_items)\n",
        "test_data_matrix = create_data_matrix(test_data, n_users, n_items)\n",
        "\n",
        "# Display the matrices to understand their structure\n",
        "print('train_data_matrix')\n",
        "print(train_data_matrix)\n",
        "print(\"number of non-zero values: \", np.sum(train_data_matrix))\n",
        "print('test_data_matrix')\n",
        "print(test_data_matrix)\n",
        "print(\"number of non-zero values: \", np.sum(test_data_matrix))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCt8PmpXCeJd"
      },
      "source": [
        "#### Step 3: Visualize the User-Item Interaction Matrices\n",
        "\n",
        "To better understand the distribution of  interactions, we’ll use a **heatmap** to visualize a subset of each user-item matrix. In the heatmap:\n",
        "- Rows represent users, and columns represent items.\n",
        "- Each cell shows whether there’s a positive interaction (`1`) or no interaction (`0`).\n",
        "- A color gradient makes it easy to spot clusters of interactions.\n",
        "\n",
        "We’ll visualize only a small portion of the interaction matrices (e.g., 50x50) to keep the display manageable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "Q1L9p0NcCeJd",
        "outputId": "a96177a3-3227-4690-b888-3a4f10eea0dc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Function to plot a heatmap for a subset of the user-item matrix\n",
        "def plot_interaction_heatmap(data_matrix, title, num_users=50, num_items=50):\n",
        "    \"\"\"\n",
        "    Plots a heatmap of a subset of the user-item interaction matrix.\n",
        "    Parameters:\n",
        "        data_matrix: The matrix to visualize.\n",
        "        title: The title of the plot.\n",
        "        num_users: The number of users to display (rows).\n",
        "        num_items: The number of items to display (columns).\n",
        "    \"\"\"\n",
        "    # Extract a subset of the matrix for visualization purposes\n",
        "    matrix_subset = data_matrix[:num_users, :num_items]\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(matrix_subset, cmap=\"YlGnBu\", cbar=True, cbar_kws={'label': 'Interaction (1 = Positive, 0 = None)'})\n",
        "    plt.xlabel('Item ID')\n",
        "    plt.ylabel('User ID')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Visualize a subset of the training and testing matrices\n",
        "plot_interaction_heatmap(train_data_matrix, 'User-Item Interaction Matrix (Train Data)')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oscd4UZoCeJd"
      },
      "source": [
        "## Task 3: Item-to-Item Collaborative Filtering with Implicit Feedback\n",
        "\n",
        "Now that we’ve prepared our data, our next task is to create a recommender system using **Item-to-Item Collaborative Filtering**. In this context, the recommendation translates to “Users who liked this item (movie) also liked …”.\n",
        "\n",
        "Since we’re working with implicit feedback, the prediction formula will focus on the **likelihood of positive interactions** rather than ratings. This will predict items the user may interact with based on similarities to items they’ve previously liked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGqXN7n1CeJd"
      },
      "source": [
        "The following formula shows how to compute the likelihood of interaction between a user $u$ and item $i$ using item-to-item colaborative filtering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0CAmSG5CCeJe"
      },
      "source": [
        "\\begin{equation}\n",
        "{p}_{u}(i) =  \\frac{\\sum\\limits_{i' \\in I} \\text{sim}(i, i') \\cdot {R}_{u}(i')}{\\sum\\limits_{i' \\in I} \\text{sim}(i, i')}\n",
        "\\end{equation}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0ZK_p8tOBSP"
      },
      "source": [
        "In the above formula:\n",
        "\n",
        "\n",
        "*   $P_u(i)$ is the likelihood of user $u$ interacting with item $i$. This is the value we want to compute.\n",
        "*   $\\text{sim}(i, i')$ is the cosine similarity between items $i$ and $i'$.\n",
        "*   $R_u(i')$ is one if user $u$ has already interacted with item $i'$. Otherwise it is zero.\n",
        "*   $I$ is the set of all items in the dataset.\n",
        "\n",
        "The value $P_u(i)$ is expected to be between 0 and 1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYOQFOCDCeJe"
      },
      "source": [
        "#### Step 1: Compute Item Similarity Matrix\n",
        "\n",
        "As a first step, we’ll calculate the pairwise similarity matrix between all items using **cosine similarity**. This matrix will show how similar each item is to every other item based on the interaction patterns of users. The output will be an `n_items` by `n_items` symmetric 2D numpy matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsMkfi7GCeJe",
        "outputId": "78be101a-8603-40b9-dfb8-1e4ffbecba1c",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Compute the item-item similarity matrix\n",
        "# Check sklearn documentation for cosine similarity to understand how we are\n",
        "# using this function.\n",
        "item_similarity = cosine_similarity(train_data_matrix.T)\n",
        "print(\"Item-Item Similarity Matrix:\")\n",
        "print(item_similarity)\n",
        "print(item_similarity.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "7bg-mTTYCeJe",
        "outputId": "2830dfe2-0978-4888-84d4-9f5675b0cafd"
      },
      "outputs": [],
      "source": [
        "# Function to visualize the item similarity matrix\n",
        "def plot_item_similarity_heatmap(similarity_matrix, title, num_items=50):\n",
        "    \"\"\"\n",
        "    Plots a heatmap of a subset of the item similarity matrix.\n",
        "    Parameters:\n",
        "        similarity_matrix: The item-item similarity matrix.\n",
        "        title: The title of the plot.\n",
        "        num_items: The number of items to display (both rows and columns).\n",
        "    \"\"\"\n",
        "    # Extract a subset of the matrix for visualization\n",
        "    matrix_subset = similarity_matrix[:num_items, :num_items]\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(matrix_subset, cmap=\"coolwarm\", cbar=True, cbar_kws={'label': 'Similarity Score'})\n",
        "    plt.xlabel('Item ID')\n",
        "    plt.ylabel('Item ID')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Visualize a subset of the item similarity matrix\n",
        "plot_item_similarity_heatmap(item_similarity, 'Item-Item Similarity Matrix')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcNdtcvVQ0MI"
      },
      "source": [
        "Let's have a look at the 2 items that have a similarity of one. Do you think they are actually similar? What do you think has happened here?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nll9EukJQniz",
        "outputId": "4ddf5fae-d37d-4cf3-a375-9c5fbae1bb45"
      },
      "outputs": [],
      "source": [
        "item_similarity[46, 37]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "3ELwXh1JCeJe",
        "outputId": "0d1474d6-a270-43b0-c8ce-617cf421e958"
      },
      "outputs": [],
      "source": [
        "# Print the item with ID 46\n",
        "display(movies[movies['movie_id'] == 46])\n",
        "\n",
        "# Print the item with ID 37\n",
        "display(movies[movies['movie_id'] == 37])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Kr58GNrCeJf"
      },
      "source": [
        "#### Step 2: Predict Positive Interactions Using Item Similarity\n",
        "\n",
        "Next, we’ll use the item similarity matrix to predict the likelihood of positive interactions for each user with each item.\n",
        "\n",
        "In what follows, we create a function that implements the above formula for item-to-item cf recommendation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUFiIfM-CeJf",
        "outputId": "31435ca7-3b9f-45cb-f1df-98f039c3ba50"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the function to predict interactions based on item similarity\n",
        "def item_based_predict(interactions, similarity, epsilon=1e-9):\n",
        "    \"\"\"\n",
        "    Predicts user-item interactions based on item-item similarity.\n",
        "    Parameters:\n",
        "        interactions (numpy array): The user-item interaction matrix.\n",
        "        similarity (numpy array): The item-item similarity matrix.\n",
        "        epsilon (float): Small constant added to the denominator to avoid division by zero.\n",
        "    Returns:\n",
        "        numpy array: The predicted interaction scores for each user-item pair.\n",
        "    \"\"\"\n",
        "    # np.dot does the matrix multiplication. Here we are calculating the\n",
        "    # weighted sum of interactions based on item similarity\n",
        "    pred = similarity.dot(interactions.T) / (similarity.sum(axis=1)[:, np.newaxis] + epsilon)\n",
        "    return pred.T  # Transpose to get users as rows and items as columns\n",
        "\n",
        "# Calculate the item-based predictions for positive interactions\n",
        "item_prediction = item_based_predict(train_data_matrix, item_similarity)\n",
        "print(\"Predicted Interaction Matrix:\")\n",
        "print(item_prediction)\n",
        "print(item_prediction.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "gPB_HiqiCeJf",
        "outputId": "5f50d0b2-5a89-481d-8231-85222fdf416c"
      },
      "outputs": [],
      "source": [
        "# Function to visualize the predicted interaction matrix for a subset of users and items\n",
        "def plot_interaction_prediction_heatmap(prediction_matrix, title, num_users=50, num_items=50):\n",
        "    \"\"\"\n",
        "    Plots a heatmap of a subset of the user-item predicted interaction matrix.\n",
        "    Parameters:\n",
        "        prediction_matrix: The predicted interaction matrix.\n",
        "        title: The title of the plot.\n",
        "        num_users: The number of users to display (rows).\n",
        "        num_items: The number of items to display (columns).\n",
        "    \"\"\"\n",
        "    # Extract a subset of the matrix for visualization\n",
        "    matrix_subset = prediction_matrix[:num_users, :num_items]\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(matrix_subset, cmap=\"YlGnBu\", cbar=True, cbar_kws={'label': 'Predicted Interaction Score'})\n",
        "    plt.xlabel('Item ID')\n",
        "    plt.ylabel('User ID')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Visualize a subset of the predicted interaction matrix\n",
        "plot_interaction_prediction_heatmap(item_prediction, 'User-Item Predicted Interaction Matrix')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtQSEyVECeJf"
      },
      "source": [
        "\n",
        "In this setup:\n",
        "- The `item_based_predict` function calculates a score for each user-item pair using the item-to-item colaborative filtering formula.\n",
        "- The result is a prediction matrix where each cell indicates the predicted likelihood of an interaction between each user and item."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wogtvY8ECeJf"
      },
      "source": [
        "## Task 4: User-to-User Collaborative Filtering with Implicit Feedback\n",
        "\n",
        "In this task, we’ll create a recommender system using **User-to-User Collaborative Filtering**. This approach translates to “Users who are similar to you also liked…”. We’ll predict the likelihood of a user interacting with an item based on the behavior of similar users."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzCwi1hYCeJl"
      },
      "source": [
        "\n",
        "#### Step 1: Compute User Similarity Matrix\n",
        "\n",
        "To start, we’ll compute the similarity matrix between users using **cosine similarity**. This matrix shows how similar each user is to every other user based on their interaction patterns. This will create a `num_users * num_users` matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESZMztZTCeJl",
        "outputId": "5c711b20-1736-4b72-f1c5-1e2b19b5f765"
      },
      "outputs": [],
      "source": [
        "# Compute the user-user similarity matrix\n",
        "user_similarity = cosine_similarity(train_data_matrix)\n",
        "print(\"User-User Similarity Matrix:\")\n",
        "print(user_similarity)\n",
        "\n",
        "# Check the shape as a sanity check\n",
        "print(\"Shape of User Similarity Matrix:\", user_similarity.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "Nliw5yY9CeJl",
        "outputId": "3f9e7ad1-f6dd-49db-fbd6-0378cba9e9f4"
      },
      "outputs": [],
      "source": [
        "# Function to plot the user similarity matrix\n",
        "def plot_user_similarity_heatmap(similarity_matrix, title, num_users=50):\n",
        "    \"\"\"\n",
        "    Plots a heatmap of a subset of the user similarity matrix.\n",
        "    Parameters:\n",
        "        similarity_matrix: The user-user similarity matrix.\n",
        "        title: The title of the plot.\n",
        "        num_users: The number of users to display (both rows and columns).\n",
        "    \"\"\"\n",
        "    # Extract a subset of the matrix for visualization\n",
        "    matrix_subset = similarity_matrix[:num_users, :num_users]\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(matrix_subset, cmap=\"coolwarm\", cbar=True, cbar_kws={'label': 'Similarity Score'})\n",
        "    plt.xlabel('User ID')\n",
        "    plt.ylabel('User ID')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Visualize a subset of the user similarity matrix\n",
        "plot_user_similarity_heatmap(user_similarity, 'User-User Similarity Matrix')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8ZUmYVQCeJl"
      },
      "source": [
        "### Step 2: Predict Positive Interactions Using User Similarity\n",
        "\n",
        "Next, we’ll use the user similarity matrix to predict the likelihood of positive interactions for each user with each item. Since we’re working with implicit feedback, we’ll calculate a score for each item based on binary interaction values (1 for positive interactions, 0 for none).\n",
        "\n",
        "The prediction formula is as follows:\n",
        "\n",
        "\\begin{equation}\n",
        "{p}_{u}(i) = \\frac{\\sum\\limits_{u' \\in U} \\text{sim}(u, u') \\cdot {R}_{u'}(i)}{\\sum\\limits_{u' \\in U} \\text{sim}(u, u')}\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "#### Explanation:\n",
        "*   $P_u(i)$ is the likelihood of user $u$ interacting with item $i$. This is the value we want to compute.\n",
        "*   $\\text{sim}(u, u')$ is the cosine similarity between users $u$ and $u'$.\n",
        "*   $R_u'(i)$ is one if user $u'$ has already interacted with item $i$. Otherwise it is zero.\n",
        "*   $U$ is the set of all users in the dataset.\n",
        "\n",
        "\n",
        "This formula calculates the likelihood of interaction between user $ u $ and item $ i $ based on interactions of similar users with that item. The weighted sum of interactions from similar users is normalized by the sum of the similarities."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mm1pJJAhCeJm"
      },
      "source": [
        "- **`similarity.dot(interactions)`**: Calculates the weighted sum of interactions for each user, based on similar users’ interactions.\n",
        "- **`np.abs(similarity).sum(axis=1)[:, np.newaxis]`**: The denominator normalizes the prediction by the sum of absolute similarities to avoid bias from users with more neighbors.\n",
        "- **`epsilon`**: Prevents division by zero, which could result in `NaN` values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E577LOFhCeJm",
        "outputId": "52eded34-d87d-41ee-a813-1d9d4dba0c93"
      },
      "outputs": [],
      "source": [
        "# Define the function to predict interactions based on user similarity\n",
        "def user_based_predict(interactions, similarity, epsilon=1e-9):\n",
        "    \"\"\"\n",
        "    Predicts user-item interactions based on user-user similarity.\n",
        "    Parameters:\n",
        "        interactions (numpy array): The user-item interaction matrix.\n",
        "        similarity (numpy array): The user-user similarity matrix.\n",
        "        epsilon (float): Small constant added to the denominator to avoid division by zero.\n",
        "    Returns:\n",
        "        numpy array: The predicted interaction scores for each user-item pair.\n",
        "    \"\"\"\n",
        "    # Calculate the weighted sum of interactions based on user similarity\n",
        "    pred = similarity.dot(interactions) / (np.abs(similarity).sum(axis=1)[:, np.newaxis] + epsilon)\n",
        "    return pred\n",
        "\n",
        "# Calculate the user-based predictions for positive interactions\n",
        "user_prediction = user_based_predict(train_data_matrix, user_similarity)\n",
        "print(\"Predicted Interaction Matrix (User-Based):\")\n",
        "print(user_prediction)\n",
        "print(user_prediction.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "_VNGoRBiCeJm",
        "outputId": "c273cd28-3119-408b-d612-348ddcc5b7cc"
      },
      "outputs": [],
      "source": [
        "# Function to visualize the predicted interaction matrix for a subset of users and items\n",
        "def plot_interaction_prediction_heatmap(prediction_matrix, title, num_users=50, num_items=50):\n",
        "    \"\"\"\n",
        "    Plots a heatmap of a subset of the user-item predicted interaction matrix.\n",
        "    Parameters:\n",
        "        prediction_matrix: The predicted interaction matrix.\n",
        "        title: The title of the plot.\n",
        "        num_users: The number of users to display (rows).\n",
        "        num_items: The number of items to display (columns).\n",
        "    \"\"\"\n",
        "    # Extract a subset of the matrix for visualization\n",
        "    matrix_subset = prediction_matrix[:num_users, :num_items]\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(matrix_subset, cmap=\"YlGnBu\", cbar=True, cbar_kws={'label': 'Predicted Interaction Score'})\n",
        "    plt.xlabel('Item ID')\n",
        "    plt.ylabel('User ID')\n",
        "    plt.title(title)\n",
        "    plt.show()\n",
        "\n",
        "# Visualize a subset of the predicted interaction matrix\n",
        "plot_interaction_prediction_heatmap(user_prediction, 'User-Item Predicted Interaction Matrix (User-Based)')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LxtVflCUCeJn"
      },
      "source": [
        "## Task 5: Evaluating Our Recommenders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKOIA-MKCeJo"
      },
      "source": [
        "#### Ranking Accurarcy (Precision@K and Recall@K)\n",
        "\n",
        "An implicit recommendation system is a ranking system which ranks items for each user based on their relevance to the user. Therefore, to evaluate such system, we’re interested in the quality of the top ranked recommendations rather than the actual predicted score for each recommendation. **Precision@K** and **Recall@K** focus on the top-K items recommended for each user, measuring relevance of the top-ranked recommended items to a user.\n",
        "\n",
        "- **Precision@K**: Measures the proportion of relevant items in the top-K recommendations.\n",
        "  \n",
        "  \\begin{equation}\n",
        "  \\text{Precision@K} = \\frac{\\text{Number of relevant items in top-K}}{K}\n",
        "  \\end{equation}\n",
        "\n",
        "- **Recall@K**: Measures the proportion of actual relevant items that appear in the top-K recommendations.\n",
        "\n",
        "  \\begin{equation}\n",
        "  \\text{Recall@K} = \\frac{\\text{Number of relevant items in top-K}}{\\text{Total number of relevant items}}\n",
        "  \\end{equation}\n",
        "\n",
        "Recall@k and Precision@k are metrics that are computed per user. To have a single value to evaluate a recommender system as a whole, we can take the average of Recall@K and Precision@K among all of the users."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Your Turn !\n",
        "\n",
        "As an exercise, complete the function precision_recall_at_k below to calculate Precision@K and Recall@K for a given value of K. Follow the instructions provided in the function to fill in the missing parts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f096JBcCeJo",
        "outputId": "8aa8d13c-55c1-4a90-fdf1-7360681196cc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# TODO: Implement the precision_recall_at_k function\n",
        "def precision_recall_at_k(prediction, ground_truth, k=10):\n",
        "    \"\"\"\n",
        "    Calculates Precision@K and Recall@K for top-K recommendations.\n",
        "    Parameters:\n",
        "        prediction (numpy array): The predicted interaction matrix with scores.\n",
        "        ground_truth (numpy array): The ground truth interaction matrix (binary).\n",
        "        k (int): Number of top recommendations to consider.\n",
        "    Returns:\n",
        "        precision_at_k (float): The average precision@K over all users.\n",
        "        recall_at_k (float): The average recall@K over all users.\n",
        "    \"\"\"\n",
        "    num_users = prediction.shape[0]\n",
        "    precision_at_k, recall_at_k = 0, 0\n",
        "\n",
        "    for user in range(num_users):\n",
        "        # Step 1: Get the indices of the top-K items for the user based on predicted scores\n",
        "        # TODO: Use np.argsort to get the top-K items for the current user\n",
        "        top_k_items = ...  # Complete this line to retrieve top-K item indices for the user\n",
        "        \n",
        "        # Step 2: Calculate the number of relevant items in the top-K items for the user\n",
        "        # TODO: Count how many of the top-K items are actually relevant (i.e., present in ground truth)\n",
        "        relevant_items_in_top_k = ...  # Complete this line to count relevant items in top-K\n",
        "        \n",
        "        # Step 3: Calculate the total number of relevant items for the user\n",
        "        # TODO: Sum the total relevant items in the ground_truth for this user\n",
        "        total_relevant_items = ...  # Complete this line to get the total relevant items\n",
        "\n",
        "        # Update Precision@K and Recall@K for this user\n",
        "        precision_at_k += relevant_items_in_top_k / k\n",
        "        recall_at_k += relevant_items_in_top_k / total_relevant_items if total_relevant_items > 0 else 0\n",
        "\n",
        "    # Step 4: Calculate the average Precision@K and Recall@K over all users\n",
        "    precision_at_k /= num_users\n",
        "    recall_at_k /= num_users\n",
        "    \n",
        "    return precision_at_k, recall_at_k\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After completing the function, you can calculate Precision@K and Recall@K for the user-based and item-based predictions as follows:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run this line after implementing the function\n",
        "precision_user_k, recall_user_k = precision_recall_at_k(user_prediction, test_data_matrix, k=10)\n",
        "precision_item_k, recall_item_k = precision_recall_at_k(item_prediction, test_data_matrix, k=10)\n",
        "\n",
        "print('User-based CF Precision@K:', precision_user_k)\n",
        "print('User-based CF Recall@K:', recall_user_k)\n",
        "print('Item-based CF Precision@K:', precision_item_k)\n",
        "print('Item-based CF Recall@K:', recall_item_k)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nRhr1MC7a2yO"
      },
      "source": [
        "## Task 6: Show the Recommendations for a Specific User\n",
        "\n",
        "Pick a user at random. Extract the top-10 recommendations for this user by both the User-to-User and Item-to-Item Collaborative Filtering models. Present the recommendations by showing the movie posters.\n",
        "\n",
        "__Hint:__ You can get the movie posters from the TMDb API. In the `links` DataFrame, you’ll find the TMDb ID corresponding to each movie. Using this ID, retrieve the movie poster and display it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 6.1: Select a User and Get Recommendations\n",
        "\n",
        "Start by selecting a user at random, and then extract the top-10 recommended movies for that user from both the User-to-User and Item-to-Item models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcKFbtO6b25l"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Step 6.2: Create Recommendation DataFrames with TMDb IDs\n",
        "\n",
        "Merge the recommendations with the `links` and `movies` DataFrames to create two DataFrames (`user_recommendations_df` and `item_recommendations_df`) with columns `movie_id`, `title`, and `tmdbId`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fetching and Displaying Movie Posters\n",
        "\n",
        "The following code uses the **TMDb API** to fetch movie posters based on the `tmdbId` of each recommended movie. The `fetch_poster` function retrieves the movie poster URL, and the `show_recommendations` function displays the posters for the top-10 recommendations. \n",
        "\n",
        "You’ll use these functions in the next step to display the movie recommendations for a specific user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install tmdbv3api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tmdbv3api import TMDb, Movie\n",
        "import pandas as pd\n",
        "\n",
        "# Set up the TMDb API with your API key\n",
        "tmdb = TMDb()\n",
        "tmdb.api_key = '37117cc09d5e00673f14f1cb7c7468b2'  # Replace with your actual TMDb API key\n",
        "\n",
        "movie_api = Movie()\n",
        "\n",
        "# Function to fetch movie posters\n",
        "def fetch_poster(tmdb_id):\n",
        "    try:\n",
        "        details = movie_api.details(tmdb_id)\n",
        "        poster_path = details.poster_path\n",
        "        return f\"https://image.tmdb.org/t/p/w200{poster_path}\" if poster_path else None\n",
        "    except:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Displaying Movie Posters for Top-10 Recommendations\n",
        "\n",
        "In this step, you’ll complete the `show_recommendations` function to display the movie posters for the top-10 recommendations for a specific user, using the `tmdbId` from the `links` DataFrame.\n",
        "\n",
        "1. **Fetch the `tmdbId`** for each movie in the recommendations:\n",
        "   - Use the `links` DataFrame to retrieve the `tmdbId` for each recommended `movie_id`.\n",
        "   - This `tmdbId` is then used to fetch the poster image via the TMDb API.\n",
        "\n",
        "2. **Fetch and Display the Poster Image**:\n",
        "   - Use the `fetch_poster` function (already defined) to get the poster URL based on the `tmdbId`.\n",
        "   - If the poster URL is available, retrieve the image using the `requests` library and display it in the subplot.\n",
        "   - If no poster is available, show a \"No Image\" placeholder text.\n",
        "\n",
        "Here’s the code with placeholders where you need to complete each step:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "def show_recommendations(recommendations, model_name):\n",
        "    \"\"\"\n",
        "    Displays the movie posters for the top-10 recommended movies.\n",
        "    \n",
        "    Parameters:\n",
        "    - recommendations: List or array of recommended movie IDs.\n",
        "    - model_name: Name of the recommendation model (e.g., \"User-to-User CF\" or \"Item-to-Item CF\").\n",
        "    \"\"\"\n",
        "    fig, axes = plt.subplots(1, len(recommendations), figsize=(20, 5))\n",
        "    fig.suptitle(f\"Top-10 Recommendations for User {user_id} - {model_name}\", fontsize=16)\n",
        "\n",
        "    for i, movie_id in enumerate(recommendations):\n",
        "        # Step 1: Fetch the `tmdbId` for the movie from the `links` DataFrame\n",
        "        # TODO: Use `movie_id` to locate the corresponding `tmdbId`\n",
        "        # TODO: Ensure `tmdb_id` is extracted as an integer\n",
        "        tmdb_id = ...  # Complete this line to retrieve the `tmdbId`\n",
        "        \n",
        "        if len(tmdb_id) == 0:\n",
        "            axes[i].axis('off')\n",
        "            continue\n",
        "\n",
        "        # Step 2: Fetch the poster URL using the `fetch_poster` function\n",
        "        # TODO: Pass `tmdb_id` to `fetch_poster` and store the result in `poster_url`\n",
        "        poster_url = ...  # Complete this line to fetch the poster URL\n",
        "        \n",
        "        # Step 3: Display the poster image if available\n",
        "        if poster_url:\n",
        "            # TODO: Retrieve and display the image\n",
        "            response = ...  # Complete this line to get the image response\n",
        "            img = Image.open(BytesIO(response.content))\n",
        "            axes[i].imshow(img)\n",
        "            axes[i].axis('off')\n",
        "        else:\n",
        "            # Display \"No Image\" placeholder text if no poster is available\n",
        "            axes[i].text(0.5, 0.5, \"No Image\", ha='center', va='center')\n",
        "            axes[i].axis('off')\n",
        "    \n",
        "    plt.show()\n",
        "\n",
        "# Example usage after completing the TODOs:\n",
        "# Display top-10 recommendations for User-to-User CF\n",
        "show_recommendations(user_top_10, \"User-to-User CF\")\n",
        "\n",
        "# Display top-10 recommendations for Item-to-Item CF\n",
        "show_recommendations(item_top_10, \"Item-to-Item CF\")\n"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
