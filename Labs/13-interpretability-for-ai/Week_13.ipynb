{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9b8849d2",
      "metadata": {},
      "source": [
        "<a href=\"https://colab.research.google.com/github/michalis0/DataScience_and_MachineLearning/blob/master/13-interpretability-for-ai/Week_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "15dc4475-7f7d-4457-8762-bb031a0629b2",
      "metadata": {
        "id": "15dc4475-7f7d-4457-8762-bb031a0629b2"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets\n",
        "import datasets\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import transformers\n",
        "!pip install shap\n",
        "import shap\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "!pip install lime\n",
        "import lime\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a844a8c0-078c-4946-8927-e570469c601c",
      "metadata": {
        "id": "a844a8c0-078c-4946-8927-e570469c601c"
      },
      "source": [
        "# Interpretability"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ZezLkv0EBybQ",
      "metadata": {
        "id": "ZezLkv0EBybQ"
      },
      "source": [
        "So far we have used various models as black boxes, where an input goes in and an output goes out.\n",
        "\n",
        "Interpretability allows us to understand what happens inside this blackbox.\n",
        "\n",
        "<img src='https://assets.spe.org/dims4/default/f6b3d58/2147483647/strip/true/crop/696x392+0+0/resize/800x451!/quality/90/?url=http%3A%2F%2Fspe-brightspot.s3.us-east-2.amazonaws.com%2Fae%2F27%2F97e3d6195614a45bed36e7a965e2%2Fblackbox.jpg' width=\"500\">"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4392fab0-671b-45ea-b27a-61a797c0e090",
      "metadata": {
        "id": "4392fab0-671b-45ea-b27a-61a797c0e090"
      },
      "source": [
        "## Content\n",
        "\n",
        "The goal of this walkthrough is to introduce explainability modules for Machine Learning models. Those allow us to better retrace the steps taken by the computer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7763984b-c9d6-43b0-ba06-fd749431aa32",
      "metadata": {
        "id": "7763984b-c9d6-43b0-ba06-fd749431aa32"
      },
      "source": [
        "## Background <a class=\"anchor\" id=\"Background\"></a>\n",
        "\n",
        "### Objective\n",
        "\n",
        "AI is often perceived as a black box. This erodes trust and makes it harder for some industries to adopt it.\n",
        "\n",
        "In order to mitigate this, XAI models (explainable AI) are being developped that allow us to retrace the steps performed by the computer."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5292f5e7-73c2-41f3-af5f-17d4dcbe9fd9",
      "metadata": {
        "id": "5292f5e7-73c2-41f3-af5f-17d4dcbe9fd9"
      },
      "source": [
        "### Examples of XAI models\n",
        "User interface examples:\n",
        "\n",
        "\n",
        "*   [Language level](http://deeptext.unice.fr/FLE/)\n",
        "*   [Emotion classification](https://shap.readthedocs.io/en/latest/example_notebooks/text_examples/sentiment_analysis/Emotion%20classification%20multiclass%20example.html)\n",
        "\n",
        "\n",
        "\n",
        "Various XAI libraries exist, the two most popular ones being `shap`and `lime`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "T6CN8f985moV",
      "metadata": {
        "id": "T6CN8f985moV"
      },
      "source": [
        "## SHAP (SHapley Additive exPlanations)\n",
        "\n",
        "**SHAP** is a popular library used for interpreting the output of machine learning models. It is based on the concept of Shapley values from cooperative game theory, which allocate the contribution of each feature to the model's predictions.\n",
        "\n",
        "### How SHAP Works:\n",
        "1. **Feature Contribution**: For each prediction, SHAP computes the contribution of each feature to the prediction by considering all possible feature combinations.\n",
        "2. **Additive Feature Attribution**: The sum of SHAP values for all features equals the modelâ€™s prediction, ensuring consistency."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35Dw0Dmg6pvT",
      "metadata": {
        "id": "35Dw0Dmg6pvT"
      },
      "source": [
        "### Example of a sentiment analisys model\n",
        "Let's start with an example of `shap` over a `Sentiment Analisys` model.\n",
        "\n",
        "For this example we will use a pretrained bert model, and we will try to identify how each feature affects the final prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "1xe8P-ehBybS",
      "metadata": {
        "id": "1xe8P-ehBybS"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# load the dataset\n",
        "dataset = datasets.load_dataset(\"emotion\", split=\"train\")\n",
        "data = pd.DataFrame({\"text\": dataset[\"text\"], \"emotion\": dataset[\"label\"]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "qC8YVIYoBybU",
      "metadata": {
        "id": "qC8YVIYoBybU"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# load the model and tokenizer\n",
        "tokenizer = transformers.AutoTokenizer.from_pretrained(\n",
        "    \"nateraw/bert-base-uncased-emotion\", use_fast=True\n",
        ")\n",
        "\n",
        "model = transformers.AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"nateraw/bert-base-uncased-emotion\"\n",
        ").cuda() # if this step fails, relaunch your google colab with a T4 runtime, ensuring cuda support\n",
        "\n",
        "# build a pipeline object to do predictions\n",
        "pred = transformers.pipeline(\n",
        "    \"text-classification\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    device=0,\n",
        "    top_k=None,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1w4aryT1BybV",
      "metadata": {
        "id": "1w4aryT1BybV"
      },
      "outputs": [],
      "source": [
        "# build an explainer function that extends our predictions pipeline\n",
        "shap_explainer = shap.Explainer(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5s-n2rB9BybW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "5s-n2rB9BybW",
        "outputId": "35ee0958-3667-4f65-b25e-b988299f3b95"
      },
      "outputs": [],
      "source": [
        "# show the explainer\n",
        "shap_values = shap_explainer([\"I am happy to be following the DSML course, although it is sad it is almost over\"])\n",
        "shap.plots.text(shap_values)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Gd-qK9h_I-t5",
      "metadata": {
        "id": "Gd-qK9h_I-t5"
      },
      "source": [
        "### Your turn!\n",
        "\n",
        "Plot a `shap` barplot that represents the weights of each word in a sentence for different emotions. You can use the documentation available [here](https://shap.readthedocs.io/en/latest/example_notebooks/text_examples/sentiment_analysis/Emotion%20classification%20multiclass%20example.html)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "j0TXSmhwbxBx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 910
        },
        "id": "j0TXSmhwbxBx",
        "outputId": "2351546e-e2ff-427e-df8e-e830f51c6b9f"
      },
      "outputs": [],
      "source": [
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Yyp4WHIgKWF8",
      "metadata": {
        "id": "Yyp4WHIgKWF8"
      },
      "source": [
        "## LIME\n",
        "We will now create a similar model using `lime` explainability over youtube spam classifications. To do so we will train a model on the labeled commets of the videos from PSY, Shakira, LMFAO and Katy Perry, and then predict if some comments are spam or not.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3y0hZOUfHYUV",
      "metadata": {
        "id": "3y0hZOUfHYUV"
      },
      "source": [
        "### Classification\n",
        "We will try to identify bellow the importance of each factor in the computers decision making.\n",
        "\n",
        "We will apply it on two models, a `Random Forest Classifier` and a `Decision Tree`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "51PeLqMiNFAR",
      "metadata": {
        "id": "51PeLqMiNFAR"
      },
      "outputs": [],
      "source": [
        "psy = pd.read_csv('https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/master/13-interpretability-for-ai/data/Youtube01-Psy.csv')\n",
        "perry = pd.read_csv('https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/master/13-interpretability-for-ai/data/Youtube02-KatyPerry.csv')\n",
        "LMFAO = pd.read_csv('https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/master/13-interpretability-for-ai/data/Youtube03-LMFAO.csv')\n",
        "Eminem = pd.read_csv('https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/master/13-interpretability-for-ai/data/Youtube04-Eminem.csv')\n",
        "Shakira = pd.read_csv('https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/master/13-interpretability-for-ai/data/Youtube05-Shakira.csv')\n",
        "full_train = pd.concat([psy, perry, LMFAO, Shakira, Eminem]).reset_index().drop(columns = ['index'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "uflWOAwjBdO0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "uflWOAwjBdO0",
        "outputId": "50ac6ef0-c8a1-4777-e842-606d28cac289"
      },
      "outputs": [],
      "source": [
        "display(full_train.head(3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fMSKevLskZvi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMSKevLskZvi",
        "outputId": "66b30ef4-22f3-4233-a68d-85e039be779e"
      },
      "outputs": [],
      "source": [
        "# Load useful libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X= full_train['CONTENT']\n",
        "y= full_train['CLASS']\n",
        "\n",
        "\n",
        "# Using default tokenizer in TfidfVectorizer\n",
        "tfidf = TfidfVectorizer(ngram_range=(1, 1), stop_words=\"english\")\n",
        "\n",
        "# Learn the vocabulary dictionary and return document-term matrix\n",
        "features = tfidf.fit_transform(X)\n",
        "\n",
        "# Visualize result in dataframe\n",
        "X = pd.DataFrame(\n",
        "    features.todense(),\n",
        "    columns=tfidf.get_feature_names_out(),\n",
        ")\n",
        "\n",
        "\n",
        "# Create Train & Test Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.fillna(0), y,test_size=0.3,\n",
        "                                                \tstratify =y,\n",
        "                                                \trandom_state = 13)\n",
        "\n",
        "# Build the model\n",
        "rf_clf = RandomForestClassifier(max_features=2, n_estimators =100 ,bootstrap = True)\n",
        "\n",
        "rf_clf.fit(X_train, y_train)\n",
        "predict_fn_clf = lambda x: rf_clf.predict_proba(x).astype(float)\n",
        "\n",
        "# Make prediction on the testing data\n",
        "y_pred = rf_clf.predict(X_test)\n",
        "\n",
        "# Classification Report\n",
        "print(classification_report(y_pred, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "DdIP42rugxAV",
      "metadata": {
        "id": "DdIP42rugxAV"
      },
      "outputs": [],
      "source": [
        "# Import the LimeTabularExplainer module\n",
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "\n",
        "# Get the class names\n",
        "class_names = ['Not spam', 'Spam']\n",
        "\n",
        "# Get the feature names\n",
        "feature_names = list(X_train.columns)\n",
        "\n",
        "# Fit the Explainer on the training data set using the LimeTabularExplainer\n",
        "lime_explainer = LimeTabularExplainer(X_train.values, feature_names =\n",
        "                                 feature_names,\n",
        "                                 class_names = class_names,\n",
        "                                 mode = 'classification')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "XNVzM-7nhRna",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "XNVzM-7nhRna",
        "outputId": "8aee279e-d75e-403c-b377-cb1a63f01f0b"
      },
      "outputs": [],
      "source": [
        "choosen_instance = X_test.loc[:].values[0]\n",
        "exp = lime_explainer.explain_instance(choosen_instance, predict_fn_clf,num_features=10)\n",
        "exp.show_in_notebook(show_all=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4UXdCBu3FiZu",
      "metadata": {
        "id": "4UXdCBu3FiZu"
      },
      "source": [
        "### Second example: Logistic regression\n",
        "\n",
        "In the context of text classification, **sincere** and **insincere** often refer to whether a question (or text) is genuine and constructive or malicious, sarcastic, or disruptive. This distinction is commonly used in datasets like Quora Question Pairs or similar platforms where user-generated content is evaluated for quality or intent.\n",
        "\n",
        "\n",
        "\n",
        "For this example we will analyse different tags on Quora posts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5y09pJkdcTcm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "id": "5y09pJkdcTcm",
        "outputId": "10a925f0-3784-4dbb-cd45-ac5420857f13"
      },
      "outputs": [],
      "source": [
        "# Paths to the split files\n",
        "file_paths = [\n",
        "    \"https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/master/13-interpretability-for-ai/data/Quora_pt1.csv\",\n",
        "    \"https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/master/13-interpretability-for-ai/data/Quora_pt2.csv\",\n",
        "    \"https://raw.githubusercontent.com/michalis0/DataScience_and_MachineLearning/master/13-interpretability-for-ai/data/Quora_pt3.csv\"\n",
        "]\n",
        "\n",
        "# Read and combine all parts\n",
        "train_df = pd.concat([pd.read_csv(path) for path in file_paths], ignore_index=True).dropna()\n",
        "\n",
        "# Display the shape and first few rows\n",
        "print(\"Train shape : \", train_df.shape)\n",
        "display(train_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "nUoQHZSfFmw-",
      "metadata": {
        "id": "nUoQHZSfFmw-"
      },
      "outputs": [],
      "source": [
        "\n",
        "## split to train and val (values to test)\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=2018)\n",
        "val_df.reset_index(drop=True)\n",
        "\n",
        "## vectorize to tf-idf vectors\n",
        "tfidf_vc = TfidfVectorizer(min_df = 10, max_features = 100000, analyzer = \"word\", ngram_range = (1, 2), stop_words = 'english', lowercase = True)\n",
        "train_vc = tfidf_vc.fit_transform(train_df[\"question_text\"])\n",
        "val_vc = tfidf_vc.transform(val_df[\"question_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "jsOTXfUJF_H6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsOTXfUJF_H6",
        "outputId": "17f33237-a02e-4707-f5d1-2c5e0545bc76"
      },
      "outputs": [],
      "source": [
        "## Training our model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(C = 0.5, solver = \"sag\")\n",
        "model = model.fit(train_vc, train_df.target)\n",
        "val_pred = model.predict(val_vc)\n",
        "\n",
        "## checking the accuracy of the model\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"accuracy score = {}\".format(accuracy_score(val_df.target, val_pred)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "p4DHY_FaLQRn",
      "metadata": {
        "id": "p4DHY_FaLQRn"
      },
      "source": [
        "Predictions and explaining one of the predictions:\n",
        "\n",
        "Some good examples of divisive questions are indexed at : 15, 163, 226, 240, 306, and 979"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "EH_Wv2pRHcJ_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EH_Wv2pRHcJ_",
        "outputId": "4b484ab5-159e-4e69-fac9-df9a787a0741"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "idx = val_df.index[979]\n",
        "\n",
        "c = make_pipeline(tfidf_vc, model)\n",
        "class_names = [\"sincere\", \"insincere\"]\n",
        "explainer = LimeTextExplainer(class_names = class_names)\n",
        "exp = explainer.explain_instance(val_df[\"question_text\"][idx], c.predict_proba, num_features = 10)\n",
        "\n",
        "print(\"Question: \\n\", val_df[\"question_text\"][idx])\n",
        "print(\"Probability (Insincere) =\", c.predict_proba([val_df[\"question_text\"][idx]])[0, 1])\n",
        "print(\"Probability (Sincere) =\", c.predict_proba([val_df[\"question_text\"][idx]])[0, 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wEug-OX-IuVW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEug-OX-IuVW",
        "outputId": "e621f31b-6688-4d8b-9191-e9f5f148be51"
      },
      "outputs": [],
      "source": [
        "exp.as_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DWy6XRsXLBkv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "DWy6XRsXLBkv",
        "outputId": "2df6c095-e7cb-42bd-9321-bfdda04276ae"
      },
      "outputs": [],
      "source": [
        "exp.show_in_notebook(text=val_df[\"question_text\"][idx], labels=(1,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yDH-su9UM0tq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "yDH-su9UM0tq",
        "outputId": "5b717f64-69ed-4bf7-a573-51502df127f5"
      },
      "outputs": [],
      "source": [
        "import collections\n",
        "\n",
        "weights = collections.OrderedDict(exp.as_list())\n",
        "lime_weights = pd.DataFrame({\"words\": list(weights.keys()), \"weights\": list(weights.values())})\n",
        "\n",
        "sns.barplot(x = \"words\", y = \"weights\", data = lime_weights)\n",
        "plt.xticks(rotation = 45)\n",
        "plt.title(\"Sample {} features weights given by LIME\".format(idx))\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
